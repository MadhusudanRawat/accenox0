# Robots.txt for Accenox
# Generated dynamically by Next.js, but this serves as a fallback

User-agent: *
Allow: /
Disallow: /admin/
Disallow: /api/
Disallow: /private/
Crawl-delay: 1

# Specific rules for search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 0

User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Sitemap location
Sitemap: https://accenox.com/sitemap.xml
